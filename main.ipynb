{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishna/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic Based FizzBuzz Function [Software 1.0]\n",
    "\n",
    "\n",
    "The logic behind Fizzbuzz program is that when there are a list of numbers then string 'Fizz' is printed when number is a multiple of 3, string 'Buzz' is printed when number is a multiple of 5, string 'Fizzbuzz' is printed when number is a multiple of 15 and String 'other' is printed when it is a number which is not divisible by any multiple of 3,5 and 15. \n",
    "\n",
    "In Software 1.0 :\n",
    "We are making use of for loop to run across numbers from 1 to 100 and if-else statement i.e \n",
    "if number is divisible by 3 \n",
    "print 'fizz'\n",
    "if number is divisible by 5 \n",
    "print 'buzz'\n",
    "if number is divisible by 15 \n",
    "print 'fizzbuzz'\n",
    "else\n",
    "print 'other'\n",
    "\n",
    "In software 2.0 \n",
    "We are solving Fizzbuzz problem by making use of Classification method which is a type of Supervised Machine Learning model that uses labeled data for learning and makes prediction to classify a new data input into a labeled group. First we are creating two csv files, one for training and the other for testing. The training csv file contains labeled data having input as numbers from 101-1000 and output in form of Fizz, Buzz, Fizzbuzz and other.\n",
    "We will convert each number into its Binary form since we have a large dataset so it is difficult to manage. Since we have numbers from 101-1000 so 10 bits will be able to cover 1000 numbers as 2pow(10)=1024. After converting integers into Binary we will make use of right shift operator to encode the dataset making it easy to process. We are making use of the concept of Neural networks where we have an input layer of 10 perceptrons and an output layer of 4 perceptrons representing our four outputs. In between our input and output layer we have a number of hidden layers. Now 10 input layer perceptrons are connected to the perceptrons of hidden layers having weights. These weights are given a random value and we perform matrix multiplication of input layer with these hidden layer weights. The output of this is passed through Activation function such as sigmoid, relu, tanh. We use error function/Cost function to check how far our output is from the expected value. If the difference of expected and predicted value is large, neurons will learn faster in case of Cross Entropy. We have used GradientDescent as optimizer to minimize the cost function by changing the value of hidden layer weights. We can make use of other Optimizers as well such as SGD, Adagrad, Adadelta, Rmsprop and Adam. The method of Backpropagation is used to reiterate across the layers multiple times so as to reduce error and improve efficiency. Number of iterations are represented by number of epochs. Batch size refers to the number of inputs feeded to neural network in one iteration, by changing batch size our accuracy gets changed. Learning Rate refers to the amount of time taken by our algorithm to learn. If we reduce value of learning rate, classifier takes longer time to learn with improved accuracy. After encoding of data and labels, i values are fed to the classifier and training of classifier takes place. After training process is complete we perform the testing phase for that we are using numbers from 1-100 as our test cases. When testing data is input to classifier, the output is in encoded form as 0,1,2,3. We decode into Fizz, Buzz, FizzBuzz and other. After that Accuracy is found by comparing expected output and neural network output based on which we are plotting a graph.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fizzbuzz(n):\n",
    "\n",
    "    # This function returns output based on whether a number is divisible by 3,5 or 15.\n",
    "    # Prints 'Fizz' when divisible by 3\n",
    "    # Prints 'Buzz' when divisible by 5\n",
    "    # Prints 'FizzBuzz' when divisible by 15\n",
    "    # else print 'other'\n",
    "    \n",
    "    if n % 3 == 0 and n % 5 == 0:   \n",
    "        return 'FizzBuzz'\n",
    "    elif n % 3 == 0:\n",
    "        return 'Fizz'\n",
    "    elif n % 5 == 0:\n",
    "        return 'Buzz'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training and Testing Datasets in CSV Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createInputCSV(start,end,filename):      # A function is defined to create a CSV file\n",
    "    \n",
    "    \n",
    "    \n",
    "   # Why list in Python?\n",
    "   # List is a data type in python that can store array of elements of different type such as int, string, float.\n",
    "   # We are storing our input and output data in a list. \n",
    "   # List makes it possible to store all data-entries in a single data object making it easy to input data in learning algorithms\n",
    "    \n",
    "    \n",
    "    inputData   = []   # List for input data of numbers\n",
    "    outputData  = []   # List for corresponding 'Fizz', 'Buzz', 'FizzBuzz' and 'other' output\n",
    "    \n",
    "    # Why do we need training Data?\n",
    "    # Since we are working on Supervised learning where an algorithm learns from an existing dataset.\n",
    "    # After that when a new input is given, it clasifies data item into a group based on its learning\n",
    "    \n",
    "    for i in range(start,end):\n",
    "        inputData.append(i)  # Adding items into the list inputData\n",
    "        outputData.append(fizzbuzz(i)) # Adding items into list outputData by passing through the fizzbuzz function  \n",
    "        \n",
    "        \n",
    "       # print(i,':',fizzbuzz(i)) : Checked the input number and corresponding output\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "    # Why Dataframe?\n",
    "    # It comes with Pandas Library. A dataframe is used to label a list of data items which will be further used as input for the training.\n",
    "    \n",
    "    dataset = {}\n",
    "    dataset[\"input\"]  = inputData  # Assigning label \"Input\" to input data\n",
    "    dataset[\"label\"] = outputData  # Assigning label \"Label\" to output data\n",
    "    \n",
    "    # Writing to csv\n",
    "    pd.DataFrame(dataset).to_csv(filename)   \n",
    "    \n",
    "    print(filename, \"Created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Input and Label Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(dataset):\n",
    "    \n",
    "    # Why do we have to process?\n",
    "    # We have 1000 data inputs, we are converting them into binary so that 10 bits can represent 1000 numbers \n",
    "    # making it easy to perform matrix multiplication with weights in neural network\n",
    "    \n",
    "    data   = dataset['input'].values   \n",
    "    labels = dataset['label'].values\n",
    "    \n",
    "    processedData  = encodeData(data)   # function call to encode data into Binary form\n",
    "    processedLabel = encodeLabel(labels) # function call to encode labels(Fizz,Buzz,FizzBuzz,other) into a 1*4 Matrix\n",
    "    \n",
    "   # for x in processedData:        # Checked output of encoded data   [1 0 1 0 0 1 1 0 0 0] - 101\n",
    "   # print(x)                                                          [0 1 1 0 0 1 1 0 0 0] - 102\n",
    "   #                                                                   [1 1 1 0 0 1 1 0 0 0] - 103\n",
    "   #                                                                   [0 0 0 1 0 1 1 0 0 0] - 104\n",
    "    \n",
    "   # for y in processedLabel:       # Checked output of encoded Label    [0.0.0.1] - FizzBuzz\n",
    "   #print(y)                                                             [0.1.0.0] - Fizz\n",
    "   #                                                                     [0.0.1.0] - Buzz\n",
    "   #                                                                     [1.0.0.0] - Other\n",
    "   # for i in processedData.Length\n",
    "   #      print(processedData[i])\n",
    "      \n",
    "    \n",
    "    return processedData, processedLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encodeData(data):\n",
    "    \n",
    "    processedData = []   # Creating a List to store encoded data items\n",
    "    \n",
    "    for dataInstance in data:\n",
    "    \n",
    "        # Why do we have number 10?\n",
    "        # We have an input of 1000 numbers so 10 bits can be used to represent 1000 numbers as 2^10=1024\n",
    "        # We require 10 bits to represent 1000 numbers\n",
    "        \n",
    "        processedData.append([dataInstance >> d & 1 for d in range(10)]) # Right shift is performed on each binary data item\n",
    "        \n",
    "        #print( ([dataInstance >> d & 1 for d in range(10)])) # Checked how data set looked after performing right shift\n",
    "    \n",
    "    return np.array(processedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeLabel(labels):\n",
    "    \n",
    "    processedLabel = []\n",
    "    \n",
    "    for labelInstance in labels:\n",
    "        if(labelInstance == \"FizzBuzz\"):\n",
    "            # Fizzbuzz\n",
    "            processedLabel.append([3])   # When Fizzbuzz is present it will be represented as [0.0.0.1]\n",
    "        elif(labelInstance == \"Fizz\"):\n",
    "            # Fizz\n",
    "            processedLabel.append([1])  # When Fizz is present it will be represented as [0.1.0.0]\n",
    "        elif(labelInstance == \"Buzz\"):\n",
    "            # Buzz\n",
    "            processedLabel.append([2])  # When Buzz is present it will be represented as [0.0.1.0]\n",
    "        else:\n",
    "            # Other\n",
    "            processedLabel.append([0])  # When Other is present it will be represented as [1.0.0.0]\n",
    "            \n",
    "    return  np_utils.to_categorical(np.array(processedLabel),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training.csv Created!\n",
      "testing.csv Created!\n"
     ]
    }
   ],
   "source": [
    "# Create datafiles\n",
    "createInputCSV(101,1001,'training.csv')  # Training file created by function call\n",
    "createInputCSV(1,101,'testing.csv')      # Testing file created by function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Dataset\n",
    "trainingData = pd.read_csv('training.csv')    # Reading Training File\n",
    "testingData  = pd.read_csv('testing.csv')     # Reading Testing File\n",
    "\n",
    "# Process Dataset\n",
    "processedTrainingData, processedTrainingLabel = processData(trainingData) # Function call \n",
    "processedTestingData, processedTestingLabel   = processData(testingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Placeholder\n",
    "inputTensor  = tf.placeholder(tf.float32, [None, 10])  # Input layer perceptron\n",
    "outputTensor = tf.placeholder(tf.float32, [None, 4])   # Output Layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_HIDDEN_NEURONS_LAYER_1 = 100 # It refers to the number of hidden layers in our neural network \n",
    "LEARNING_RATE = 0.5      # Amount of time Algorithm takes to learn\n",
    "                         # Lower the learning rate longer it will take to learn but will give more accurate results.\n",
    "\n",
    "# Initializing the weights to Normal Distribution\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape,stddev=0.01)) # Random initialisation of weights with standard Deviation of 0.01  \n",
    "\n",
    "# Initializing the input to hidden layer weights\n",
    "input_hidden_weights  = init_weights([10, NUM_HIDDEN_NEURONS_LAYER_1]) # Function call to initialise input layer weight \n",
    "# Initializing the hidden to output layer weights  \n",
    "hidden_output_weights = init_weights([NUM_HIDDEN_NEURONS_LAYER_1, 4]) # Function call to initialise output layer weight\n",
    "\n",
    "# Computing values at the hidden layer\n",
    "hidden_layer = tf.nn.relu(tf.matmul(inputTensor, input_hidden_weights))\n",
    "\n",
    "\n",
    "# Rectified Linear Unit(Relu) is an activation function that gives:\n",
    "#(1) output as 0 for negative values of the product of (input and weights)\n",
    "#(2) output as the product(input*weights) itself for a value >0\n",
    "\n",
    "#Instead of Activation Function Relu we can make use of other Activation functions such as Tanh(), Sigmoid()\n",
    "# Matmul is used for matrix multiplication of input perceptron with the hidden layer weights\n",
    "\n",
    "# Computing values at the output layer \n",
    "output_layer = tf.matmul(hidden_layer, hidden_output_weights)\n",
    "\n",
    "# Defining Error Function\n",
    "\n",
    "# We use error function to check how far our output is from the expected value.\n",
    "# We are using cross entropy as the cost/error function\n",
    "# We can use Quadratic Cost but it will slow down our learning speed\n",
    "# If the difference of expected and predicted value is large, neurons will learn faster in case of Cross Entropy\n",
    "\n",
    "error_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output_layer, labels=outputTensor))\n",
    "\n",
    "# Defining Learning Algorithm and Training Parameters\n",
    "\n",
    "# We have used GradientDescent as optimizer to minimize the cost function by changing the value of hidden layer weights\n",
    "# we can make use of other Optimizers as well such as SGD, Adagrad, Adadelta, Rmsprop and Adam.\n",
    "\n",
    "training = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(error_function)\n",
    "\n",
    "# Prediction Function\n",
    "prediction = tf.argmax(output_layer, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_EPOCHS = 2500 # No. of times we feed in our batch of data\n",
    "BATCH_SIZE = 125 # Amount of data we feed in one iteration\n",
    "\n",
    "training_accuracy = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Set Global Variables ?\n",
    "    tf.global_variables_initializer().run()  # Initialise the variables for Tensor Flow like tf.Placeholder(tf.float32),[None,10]\n",
    "    \n",
    "    for epoch in tqdm_notebook(range(NUM_OF_EPOCHS)):\n",
    "    \n",
    "        \n",
    "        #Shuffle the Training Dataset at each epoch\n",
    "        p = np.random.permutation(range(len(processedTrainingData))) # Randomising value for training data\n",
    "        processedTrainingData  = processedTrainingData[p]\n",
    "        processedTrainingLabel = processedTrainingLabel[p]\n",
    "        \n",
    "        # Start batch training\n",
    "        for start in range(0, len(processedTrainingData), BATCH_SIZE):\n",
    "            end = start + BATCH_SIZE\n",
    "            sess.run(training, feed_dict={inputTensor: processedTrainingData[start:end], \n",
    "                                          outputTensor: processedTrainingLabel[start:end]})\n",
    "        # Training accuracy for an epoch                           # Training of model\n",
    "        training_accuracy.append(np.mean(np.argmax(processedTrainingLabel, axis=1) ==  \n",
    "                             sess.run(prediction, feed_dict={inputTensor: processedTrainingData,\n",
    "                                                             outputTensor: processedTrainingLabel})))\n",
    "    # Testing\n",
    "    predictedTestLabel = sess.run(prediction, feed_dict={inputTensor: processedTestingData})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()     # Creating Graph\n",
    "df['acc'] = training_accuracy\n",
    "df.plot(grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decodeLabel(encodedLabel):\n",
    "    if encodedLabel == 0:  # if encoded output is 0 print Other\n",
    "        return \"Other\"\n",
    "    elif encodedLabel == 1: # if encoded output is 1 print Fizz\n",
    "        return \"Fizz\"\n",
    "    elif encodedLabel == 2: # if encoded output is 2 print Buzz\n",
    "        return \"Buzz\"\n",
    "    elif encodedLabel == 3: # if encoded output is 3 print FizzBuzz\n",
    "        return \"FizzBuzz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model [Software 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong   = 0\n",
    "right   = 0\n",
    "\n",
    "predictedTestLabelList = []\n",
    "\n",
    "for i,j in zip(processedTestingLabel,predictedTestLabel):\n",
    "    predictedTestLabelList.append(decodeLabel(j))     # Function call for printing output based on encoded data 0,1,2,3\n",
    "    \n",
    "    if np.argmax(i) == j:  \n",
    "        right = right + 1 # If predicted value is right, increment variable right\n",
    "    else:\n",
    "        wrong = wrong + 1 # If predicted value is wrong, increment variable wrong\n",
    "\n",
    "print(\"Errors: \" + str(wrong), \" Correct :\" + str(right))\n",
    "\n",
    "print(\"Testing Accuracy: \" + str(right/(right+wrong)*100))  # Checking the Accuracy of the output by formulae\n",
    "\n",
    "# Please input your UBID and personNumber \n",
    "testDataInput = testingData['input'].tolist()\n",
    "testDataLabel = testingData['label'].tolist()\n",
    "\n",
    "testDataInput.insert(0, \"UBID\")\n",
    "testDataLabel.insert(0, \"ksehgal\")\n",
    "\n",
    "testDataInput.insert(1, \"personNumber\")\n",
    "testDataLabel.insert(1, \"50291124\")\n",
    "\n",
    "predictedTestLabelList.insert(0, \"\")\n",
    "predictedTestLabelList.insert(1, \"\")\n",
    "\n",
    "output = {}\n",
    "output[\"input\"] = testDataInput\n",
    "output[\"label\"] = testDataLabel\n",
    "\n",
    "output[\"predicted_label\"] = predictedTestLabelList\n",
    "\n",
    "opdf = pd.DataFrame(output)\n",
    "opdf.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
